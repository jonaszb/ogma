# Ogma

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

Ogma is a tool that generates README files for GitHub repositories based on their contents and additional information provided by the user. It uses the power of GPT to generate the markdown in chunks, allowing users to copy or download the generated README.

## Features

-   Generates professional README files for GitHub repositories
-   Utilizes Server-Sent Events (SSE) to create the markdown in chunks as it is generated by GPT
-   Provides the ability to copy or download the generated markdown

## Built With

Ogma is built with the following technologies:

-   FastAPI backend, which uses GPT to generate the README
-   Vue.js, Vite, and TypeScript frontend for a responsive and interactive user interface
-   Nginx as web server and reverse proxy
-   Docker for containerization and easy deployment

## Getting Started

To run Ogma, you will need to set the following environment variables:

-   `GITHUB_TOKEN`: GitHub token for accessing the GitHub API
-   `OPENAI_API_KEY`: OpenAI API key for utilizing GPT

There are two ways to run Ogma:

1. The recommended way is to use `docker-compose`. This method creates a separate container for each service. To run Ogma with `docker-compose`, execute the following command:

    ```bash
    docker compose up --build
    ```

2. The alternative method is to use a single Dockerfile located in the project's root directory. This approach creates all services within a single container, simplifying hosting. To run Ogma using this method, build and run the Docker container.

    ```bash
    docker build -t ogma .
    docker run -p 80:80 -e GITHUB_TOKEN=<your_github_token> -e OPENAI_API_KEY=<your_openai_api_key> ogma
    ```

Please note that Ogma is best suited for small or medium-sized repositories.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
